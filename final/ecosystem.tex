\vspace{-0.25em}
\section{Gdev Ecosystem}
\label{sec:ecosystem}
\vspace{-0.25em}

\begin{figure}[t]
 \begin{center}
  \includegraphics[width=\hsize]{eps/gdev.eps}\\
  \vspace{-0.5em}
  \caption{Logical view of Gdev's ecosystem.}
  \label{fig:gdev}
 \end{center}
 \vspace{-1.5em}
\end{figure}

Gdev aims to (i) enhance GPU resource management and (ii) extend a class
of applications that can leverage GPUs.
To this end, we integrate the major portion of runtime support into the OS.
Figure~\ref{fig:gdev} illustrates the logical view of Gdev's ecosystem.
For a compatibility issue, we still support the conventional stack where
applications make API calls to the user-space runtime library, but
system designers may disable this stack to remove the concern discussed in
Section~\ref{sec:introduction}.
A new ecosystem introduced by Gdev is runtime support integrated in
the OS, allowing the user space as well as the OS to use the identical
API set.
This ecosystem prevents non-privileged user-space programs from
bypassing the runtime system to access GPUs.
The wrapper library is a small piece of software provided for user-space
applications, which relays API calls to the runtime system employed in the OS.

Leveraging this ecosystem, we design an API-driven GPU resource
management scheme.
Figure~\ref{fig:gdev} shows that Gdev allows the OS to manage
API calls, whereas the traditional model translates API calls to GPU
commands before the OS receives them.
As discussed in previous work~\cite{Kato_ATC11}, it is very hard to
analyze GPU commands and recognize the corresponding API calls in the
OS.
Hence, the existing GPU resource management schemes in the
OS~\cite{Bautin_MCNC08, Kato_ATC11} compromise overhead to invoke the
scheduler at every GPU command submission, unless an additional
programming abstraction is provided~\cite{Rossbach_SOSP11}.
On the other hand, Gdev can manage GPU resources along with API calls,
without any additional programming abstractions.

\textbf{Programming Model:}
We provide a set of low-level functions for GPGPU programming, called
``Gdev API''.
Gdev API is a useful backend for high-level APIs, such as CUDA.
The details of Gdev API can be found at our project website~\cite{Gdev}.
Programmers may use either Gdev API directly or high-level APIs built
on top of Gdev API.
This paper particularly assumes that programmers use the well-known CUDA
Driver API 4.0~\cite{CUDA40}.

Gdev uses an existing programming framework and commodity compiler, such
as NVIDIA CUDA Compiler (NVCC)~\cite{CUDA40}.
When a program is compiled, two pieces of binary are generated.
One executes on the CPU, and loads the other binary onto the GPU.
The CPU binary is provided as an executable file or loadable module,
while the GPU binary is an object file.
Hence, both user-space and OS-space applications can use the same
framework: (i) read the GPU binary file and (ii) load it onto the GPU.
The detailed information embedded in the object file, such as code,
static data, stack size, local memory size, and parameter format, may
depend on the programming language, but the framework does not depend on
it once the object file is parsed.

\textbf{Resource Management:}
We provide device memory management and GPU scheduling schemes to manage
GPUs as first-class computing resources.
Specifically, we provide shared device memory for IPC, data swap for
large memory demands, resource-based queuing for throughput, and
bandwidth-aware resource partitioning for virtual GPU isolation.
Since some of these features require access to low-level system
information, such as I/O regions, DMA pages, and task control blocks, it
is not straightforward for the traditional user-space runtime system to
manage these pieces of information.
Hence, we claim that Gdev is a suitable approach to first-class GPU
resource management.
The concept of Gdev is also not limited to GPUs, but can be
generalized for a broad class of heterogeneous compute devices.


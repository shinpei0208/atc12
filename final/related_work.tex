\vspace{-0.25em}
\section{Related Work}
\label{sec:related_work}
\vspace{-0.25em}

\textbf{GPU Resource Management:}
TimeGraph~\cite{Kato_ATC11} and GERM~\cite{Bautin_MCNC08} provide a GPU
command-driven scheduler integrated in the device driver.
Specifically, TimeGraph achieves a prioritization and isolation scheme,
extended with a resource sharing scheme~\cite{Kato_RTAS11} later on,
whereas GERM enhances fair-share GPU resource control.
Gdev also respects a prioritization, isolation, and fairness scheme,
similar to TimeGraph and GERM, but adopts an API-driven scheduler model
to reduce the number of scheduler invocations.
The overhead of the command-driven scheduler model was
also discussed in \cite{Kato_ATC11}.


PTask~\cite{Rossbach_SOSP11} is an OS abstraction for GPU applications
that optimizes data transfers between host and device memory using
a data-flow programming model and a GPU scheduler.
CGCM~\cite{Jablin_PLDI11} is another solution based on the compiler and
runtime library that dynamically and automatically optimizes the same
sort of data trasfers.
In contrast, Gdev does not support data-flow programming or automatic
code generation.
Alternatively, it provides programmers with an explicit API set to share
device memory among GPU contexts.
Such an IPC scheme can similarly reduce data transfer overhead.

RGEM~\cite{Kato_RTSS11} is a user-space runtime model for real-time
GPGPU applications.
It creates preemption points with data transfers between host and device
memory in order to bound blocking times imposed on high-priority tasks.
It also provides separate queues to demultiplex the schedulings of data
transfers and computations.
Albeit using a similar separate-queue scheme, Gdev addresses a core
challenge of GPU resource management integreated in the OS to overcome
the user-space limitations.

In addition to the differences described above, Gdev can virtualize the
GPU in the OS, which enables users to view a physical GPU as multiple
logical GPUs for strong resource isolation.
None of the previous work has also devided compute and memory
bandwidth reservations, whereas Gdev accounts for these bandwidth
reservations independently to maximize the overall GPU utilization.
Furthermore, the previous work depend more or less on proprietary
software or existing software stack, which could force design and
implementation, if not concept, to adhere to user-space runtime
libraries.
Our prototype design and implementation of Gdev, in contrast, is fully
self-contained, allowing the OS to fully control and even use GPUs as
first-class computing resources.

\begin{comment}
Comparisons of Gdev and representatives of the above GPU resource
management approaches are summarized in Table~\ref{tab:related_work}.
\begin{table*}[t]
 \caption{Comparisons of Gdev and prior GPU resource management
 approaches.}
 \label{tab:related_work}
 \begin{center}
  {\sf
  \begin{tabular}{|l|p{12.8cm}|}
   \hline
   \hline
  \end{tabular}
  }
 \end{center}
\vspace{-1em}
\end{table*}
\end{comment}

\textbf{GPUs as OS Resources:}
A significant limitation on the current GPU programming framework is
that GPU applications must reside in the user space.
KGPU~\cite{Sun_SYSTOR12} is a combination of the OS kernel
module and user-space daemon, which allows the OS to use GPUs by
up-calling the user-space daemon from the OS to access the GPU.
On the other hand, Gdev provides OS modules with a set of traditional
API functions for GPU programming, such as CUDA.
Hence, a legacy GPU application program can execute in the OS, as it is,
without any modifications and additional communications between the user
space and the OS.
In addition, we have shown that runtime support integrated in the OS is
more reliable.

\textbf{GPU Virtualization:}
VMGL~\cite{Lagar-Cavilla_VEE07} virtualizes GPUs at the OpenGL
API level, and VMware's Virtual GPU~\cite{Dowty_SIGOPS09} exhibits I/O
virtualization through graphics runtimes.
On the other hand, Pegasus~\cite{Gupta_ATC11} uses a hypervisor,
Xen~\cite{Barham_SOSP03} in particular, to co-schedule GPUs and virtual
CPUs in VMs.
Nonetheless, these virtualization systems rely on user-space runtimes
provided by proprietary software, preventing the system from managing
GPU resources in a fine-grained manner. 
In addition, they are mainly designed to make GPUs available in
virtualized environments, but are not tailored to isolate GPU resources
among users.
Gdev provides virtual GPUs with strong time and space partitioning, and
hence could underlie these GPU virtualization systems.

\textbf{I/O Scheduling:}
GPU scheduling deals with a non-preemptive nature of execution as well
as traditional I/O scheduling.
Several disk bandwidth-aware schedulers~\cite{Gulati_FAST09,
Povzner_EUROSYS08, Wang_FAST07}, for example, contain a similar idea to
the Gdev scheduler.
Unlike typical I/O devices, however, GPUs are coprocessors operating
asynchronously with own sets of execution contexts, registers, and memory.
Therefore, Gdev adopts a scheduling algorithm more appropriate for
compute-intensive workload.

\textbf{Compile-Time and Application Approaches:}
GPU resources can also be managed by application
programs without using drivers and
libraries~\cite{Chen_IPDPS10,Guevara09,Saba_RTSS11}.
However, these approaches essentially need to modify or recompile the
programs using specific compilers and/or algorithms.
Thus, a generality of programming frameworks need to be compromised.
In contrast, Gdev allows applications to use traditional GPU programming
frameworks.


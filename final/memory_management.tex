\vspace{-0.25em}
\section{Device Memory Management}
\label{sec:memory_management}
\vspace{-0.25em}

Gdev manages device memory using the virtual memory management unit
supported by the GPU.
Virtual address space for GPU contexts can be set through the page
table.
Gdev stores this page table in device memory, though it can also be
stored in host memory.
Beyond such basic pieces of memory management, this section seeks how to
improve memory-copy throughput.
We also explore how to share memory resources among GPU contexts, and
support data swap for large device memory demands.

\vspace{-0.25em}
\subsection{Memory-Copy Optimization}
\label{sec:memory_copy}
\vspace{-0.25em}

As data need to move across device and host memory in GPU applications, 
the memory-copy throughput could govern overall application performance.
The goal of this paper is to enhance GPU resource management, but
we still respect standalone performance, since it relates to a practical
use of our solution in the real world.
Hence, we first study the characteristic of memory-copy operations.

\textbf{Split Transaction:}
We often need to copy the same data set twice to communicate with the
GPU, unless we allocate buffers to host I/O memory directly.
One copy happens within host memory to move data between main memory
and I/O memory that is accessible to the GPU.
The other copy then happens between device and host I/O memory.
In order to optimize this two-step memory-copy operation, we split each
operation into a fixed size of chunks.
While some chunk is transferred within host memory, the preceding chunk
can be transferred between device and host I/O memory.
In this way, only the first and last pieces of chunks need to be
transferred alone, and other chunks are all overlapped, thus reducing a
total makespan almost half.
This split transaction approach also has an advantage that we need only
a small size of intermediate ``bounce'' buffers on host I/O memory equal
to the chunk size, thus reducing the usage of host I/O memory
significantly.

\textbf{Direct I/O Access:}
The split transaction is effective for a large size of data.
For a small size of data, however, the use of DMA engines incurs
non-trivial overhead by itself.
Hence, we also employ a method to read/write data one by one by mapping
device memory space onto host I/O memory space, rather than send/receive
data in burst mode by using DMA engines.
We have found that direct I/O access is much faster than DMA transaction
for a small size of data.
In Section~\ref{sec:evaluation}, we will identify a boundary on the data
size that inverts the latency of I/O access and DMA, and also derive the
best chunk size to optimize memory-copy throughput.

\vspace{-0.25em}
\subsection{Shared Device Memory}
\label{sec:shared_memory}
\vspace{-0.25em}

Existing GPU programming languages do not support an explicit API
for IPC.
For example, data communication among GPU contexts incurs significant
overhead due to copying data back and forth between device and host
memory.
Currently, an OS dataflow abstraction~\cite{Rossbach_SOSP11} is a useful
approach to reduce such data movement costs; users are required to use a
dataflow programming model.
We believe that it is more flexible for programmers to
use a familiar method, such as a POSIX IPC mechanism.

Gdev supports a set of API functions to share memory resources among GPU
contexts, respecting a POSIX IPC design of \texttt{shmget},
\texttt{shmat}, \texttt{shmdt}, and \texttt{shmctl}.
As a high-level API, we extend CUDA  to provide new API functions of
\texttt{cuShmGet}, \texttt{cuShmAt}, \texttt{cuShmDt}, and
\texttt{cuShmCtl} in our CUDA implementation so that CUDA
applications can easily leverage Gdev's shared device memory
functionality.

Our shared memory design is straightforward, though its implementation
is challenging.
Suppose that we use the above extended CUDA API for IPC.
Upon the first call to \texttt{cuShmGet}, Gdev allocates new space to
device memory, and holds an identifier to this memory object. 
After the first call, Gdev simply returns this identifier to this call.
When \texttt{cuShmAt} is called, the allocated space is mapped to the
virtual address space of the corresponding GPU context.
This address mapping is done by setting the page table so that the
virtual address points to the physical memory space of this shared
memory object.
The allocated space can be unmapped by \texttt{cuShmDt} and freed by
\texttt{cuShmCtl}. 
If the shared memory object needs exclusive access, the host program
running on the CPU must use traditional mutex/semaphore mechanisms.

\vspace{-0.25em}
\subsection{Memory Swapping}
\label{sec:memory_swapping}
\vspace{-0.25em}

We have found that proprietary software in Linux~\cite{CUDA40} fails to
allocate device memory exceeding the physical memory capacity, while
PTask~\cite{Rossbach_SOSP11} claims that Windows software can somehow
swap device memory.
In either case, however, it is not well studied how to swap device
memory and speed up its operation.

Gdev uses the shared device memory functionality to achieve data
swapping.
When memory allocation fails due to a short of free memory
space, Gdev seeks memory objects whose allocated size is greater than
the requested size, and selects one owned by a low-priority context,
where ties are broken arbitrarily.
This ``victim'' memory object is shared by the caller context 
\textit{implicitly}.
Unlike an explicit shared memory object obtained through the API
presented in Section~\ref{sec:shared_memory}, an implicit shared memory
object must evict data when accessed by other contexts, and retrieve
them later when the corresponding context is resumed.
Since Gdev is designed API-driven, we know when contexts may access the
shared memory object:
\begin{itemize}
 \vspace{-0.25em}
 \item The memory-copy API will affect specific address space given by
       the API parameters.
       Hence, we need to evict only such data that cover this range.

 \vspace{-0.5em}
 \item The compute-launch API may also be relevant to some address
       space, but its address range is not all specified when the API is
       called, since the program may use dynamic memory allocation.
       Hence, we need to evict such data that are associated with all
       the memory objects owned by the context.
 \vspace{-0.25em}
\end{itemize}

We allocate swap buffers to host main memory for evicted data.
Swapping itself is a simple asynchronous memory-copy operation, but is
not visible to application programs.
It should be noted that swapping does not occur when copying data from
device memory to host memory.
If the corresponding data set is evicted in the swap space, we can just
copy them from the swap space to the user buffer directly, and there is
no need to swap them back to device memory.

\textbf{Reducing Latency:}
It is apparent that the swapping latency could be non-trivial, depending
on the data size.
In order to reduce this latency, Gdev reserves a certain amount of
device memory space as \textit{temporal swap space}.
Since a memory-copy operation within device memory is much faster than
that between device and host memory, Gdev tries to evict data to the
temporal swap space first.
This temporarily-evicted data set is eventually evicted to host memory
after a while to free up the swap space for other contexts. 
Gdev also tries to hide this second eviction latency by overlapping it
with GPU computation launched by the same context.
We create a special GPU context that is dedicated to memory-copy
operations for eviction, since the compute and DMA units cannot be used
by the same context simultaneously.
This approach is quite reasonable because data eviction is likely to be
followed by GPU computation.
Evicted data, if exist, must be retrieved before GPU computation is
launched. 
If they remain in the swap space, they can be retrieved at low cost.
Else, Gdev retrieves them from host memory.

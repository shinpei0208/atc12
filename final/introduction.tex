\vspace{-0.25em}
\section{Introduction}
\label{sec:introduction}
\vspace{-0.25em}

Recent advances in many-core technology have achieved an
order-of-magnitude gain in computing performance.
Examples include \textit{graphics processing units} (GPUs) -- mature
compute devices that best embrace a concept of heterogeneous many-core
computing.
In fact, TOP500 Supercomputing Sites disclosed in November
2011~\cite{TOP500} that three of the top five supercomputers employ
clusters of GPUs as primary computing resources.
Of particular note is that scientific climate applications have achieved
80x speedups leveraging GPUs~\cite{Shimokawabe10}.
Such a continuous series of evidence on performance benefits of GPUs has
encouraged application domains of GPUs to expand to general-purpose and
embedded computing.
For instance, previous work have demonstrated that GPU-accelerated
systems achieved an order of 10x speedups for software
routers~\cite{Han_SIGCOMM10}, 20x speedups for encrypted
networks~\cite{Jang_NSDI11}, and 15x speedups for motion planning~\cite{McNaughton_ICRA11}.
This rapid growth of general-purpose computing on GPUs,
\textit{a.k.a.}, GPGPU, is brought by recent advances in programming
languages, such as CUDA~\cite{CUDA40}.

Seen from these trends, GPUs are becoming more and more applicable for
general-purpose systems.
However, system software support for GPUs in today's market is
tailored to accelerate particular applications dedicated to the
system; it is not well-designed to integrate GPUs into general-purpose
\textit{multi-tasking} systems.
Albeit speedups of individual application programs, the previous
research raised above~\cite{Han_SIGCOMM10, Jang_NSDI11,
McNaughton_ICRA11} could not provide performance or quality-of-service
(QoS) management without system software support.
Given that networked and embedded systems are essentially composed
of multiple clients and components, it is essential that GPUs be
managed as first-class computing resources in order for them to be
used by multiple tasks concurrently in a reliable manner.

The research community has articulated the needs of enhancement in 
the operating system (OS)~\cite{Bautin_MCNC08, Kato_ATC11,
Rossbach_SOSP11}, hypervisor~\cite{Gupta_ATC11}, and runtime
library~\cite{Kato_RTSS11} to make GPUs available in interactive
and/or virtualized multi-tasking environments.
However, all these pieces of work depend highly on the user-space runtime
engine, often included as part of proprietary software, which provides
the user space with an application programming interface (API).
This framework limits the use of GPUs only within the user space.
For example, it prevents the file system or network stack in the OS from
using GPUs directly.
There is another issue of concern with this framework.
Since runtime support is employed in the user space, the device
driver needs to expose resource management primitives to the user space,
which implies that non-privileged user-space programs may abuse GPU
resources.
As a matter of fact, we can launch any program on an NVIDIA GPU without
using any user-space runtime libraries, but using an \texttt{ioctl}
system call directly. 
This explains that GPUs should be protected by the OS as well as CPUs.

In addition to those conceptual issues, there exist more fundamental and
practical issues with publicly-available GPGPU software.
For example, memory allocation for GPU computing is not allowed to
exceed the physical capacity of device memory.
We are also not aware of any API that allows GPU contexts to share
memory resources with other contexts.
Such data management constraints may not be acceptable in
general-purpose programming.

\textbf{Contribution:}
We present \textbf{Gdev}, a new approach to GPU resource management in
the OS that
addresses the current limitations of GPU computing.
Gdev integrates runtime support for GPUs into the OS, which allows the
user space as well as the OS itself to use GPUs with the identical API
set, while protecting GPUs from non-privileged user-space programs at
the OS level.
Building on this runtime-unified OS model, Gdev further provides
first-class GPU resource management schemes for multi-tasking systems.
Specifically, Gdev allows programmers to share device memory resources
among GPU contexts using an explicit API.
We also use this shared memory functionality to enable GPU contexts to
allocate memory exceeding the physical size of device memory.
Finally, Gdev is able to virtualize the GPU into multiple logical
GPUs to enhance an isolation among working groups of multi-tasking
systems.
A proof of concept is provided as an open-source implementation of Gdev.
In summary, this paper makes the following contributions:

\begin{itemize}
 \vspace{-0.25em}
 \item Identifies the advantage/disadvantage of integrating runtime
       support for GPUs into the OS.
 \vspace{-0.5em}
 \item Enables the OS itself to use GPUs.
 \vspace{-0.5em}
 \item Makes GPUs as first-class computing resources in multi-tasking
       systems -- memory management and scheduling for inter-process
       communication (IPC) and GPU virtualization.
 \vspace{-0.5em}
 \item Provides open-source implementations of the GPU device driver,
       runtime/API libraries, utility tools, and Gdev resource
       management components.
 \vspace{-0.5em}
 \item Demonstrates the capabilities of Gdev using real-world benchmarks
       and applications.
 \vspace{-0.25em}
\end{itemize}

\textbf{Organization:}
The rest of this paper is organized as follows.
Section~\ref{sec:model} provides the model and assumptions behind
this paper.
Section~\ref{sec:ecosystem} outlines the concept of Gdev.
Section~\ref{sec:memory_management} and \ref{sec:scheduling} present
Gdev memory management and scheduling schemes.
Section~\ref{sec:implementation} describes our prototype implementation,
and Section~\ref{sec:evaluation} demonstrates our detailed experimental
results.
Section~\ref{sec:related_work} discusses related work.
We provide our concluding remarks in Section~\ref{sec:conclusion}.

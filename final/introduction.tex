\vspace{-0.5em}
\section{Introduction}
\label{sec:introduction}
\vspace{-0.25em}

Recent innovations in heterogeneous compute devices with many-core
technology have achieved an order-of-magnitude gain in computing
performance. 
In particular, the graphics processing unit (GPU) receives considerable
attention as a mature heterogeneous compute device that embraces a
concept of many-core computing.
A recent announcement from the TOP500 supercomputing sites in November
2011~\cite{TOP500} disclosed that three of the top five supercomputers
use GPUs.
For example, scientific climate applications can gain 80x speedups using
such GPU-based supercomputers~\cite{Shimokawabe10}.
The benefit of GPUs appears not only in high-performance computing but
also in general-purpose and embedded computing domains.
According to previous research, GPUs can achieve up to an order of 10x
speedups for software routers~\cite{Han_SIGCOMM10}, 20x speedups for
encrypted networks~\cite{Jang_NSDI11}, and 15x speedups for motion
planning in autonomous vehicles~\cite{McNaughton_ICRA11}.
Such a rapid growth of general-purpose computing on GPUs,
\textit{a.k.a.}, GPGPU, is brought by recent advances in GPU
programming languages, such as CUDA~\cite{CUDA40}.

As these trends show, GPUs are becoming more and more useful in
general-purpose domains. 
Nonetheless, system software support for GPUs in today's market is
tailored to accelerate particular applications dedicated to the
system; it is not well-designed to integrate GPUs into more
general-purpose multi-tasking systems.
Although the previous work raised above~\cite{Han_SIGCOMM10,
Jang_NSDI11, McNaughton_ICRA11} have drawn improvements in performance
achieved by GPUs, they could never provide performance or
quality-of-service (QoS) management without system software primitives.
Given that those networked and embedded systems are typically composed
of multiple clients and components, it is essential to manage GPUs as
first-class computing resources so that they can be accessed by multiple
tasks simultaneously in a reliable manner.

The research community has articulated the needs of enhancement in 
the operating system (OS)~\cite{Bautin_MCNC08, Kato_ATC11,
Rossbach_SOSP11}, hypervisor~\cite{Gupta_ATC11}, and runtime
library~\cite{Kato_RTSS11} to make GPUs available in interactive
and/or virtualized multi-tasking environments.
However, all these pieces of work depend highly on the user-space runtime
engine, often included as part of proprietary software, which provides
the user space with an application programming interface (API).
This framework limits the use of GPUs only within the user space.
For example, it prevents the file system or network stack in the OS from
using GPUs directly.
There is also another issue of concern in the this framework.
Employing runtime support in the user space requires the device driver
to expose resource management primitives to the user space.
This implies that any non-prilileged user-space programs may abuse the
GPU resource. 
As a matter of fact, we can execute a program on an NVIDIA GPU without
using any user-space runtime libraries, but using a \texttt{ioctl}
system call directly. 
We believe that GPUs should be protected by the OS as well as CPUs.

Apart from those conceptual issues, there are more fundamental and
practical issues in publically available software for GPUs.
For example, memory allocation for GPU computing is not allowed to
exceed the size of physical device memory.
We are also not aware of any API that allows GPU contexts to share
memory resources with others.
Such constraints in data management may not be acceptable in
general-purpose programming.

This paper presents \textbf{Gdev}, a new GPGPU ecosystem that addresses
the current limitations of GPU resource management.
Specifically, Gdev integrates GPU runtime support, including the API,
into the OS to allow a wide class of user-space applications and the OS
itself to use GPUs in a reliable manner.
While OS applications can directly call the API, user-space
programs can also use it through the system call, such as
\texttt{ioctl}.
We also provide an implementation of CUDA API~\cite{CUDA40} wrapping
Gdev API so that legacy CUDA applications can work with Gdev in both the
user space and the OS.
This runtime-unified OS approach forces GPU applications running in
the same system to be managed by the identical resource management
entity, which eliminates the concern about malicious programs attempting
to access GPUs directly.
The contributions of Gdev also include first-class support for GPU
resource management in time-sharing systems.
Specifically, Gdev allows programmers to share device memory resources
among GPU contexts explicitly using the API. 
We also leverage this shared memory scheme to allow the system to allocate
data beyond the size of physical memory space, exploiting implicit data
eviction and reload between the host and device memory.
Moreover, Gdev devises virtual GPU support to isolate GPU users in
time-sharing systems, using a new GPU scheduler to deal with the
non-preemptive and burst nature of GPU workloads.
As a proof-of-concept, we finally provide an open-source implementation of Gdev,
including a device driver and runtime/API library.
In summary, this paper makes the following contributions:

\begin{itemize}
 \vspace{-0.25em}
 \item Identifies the advantage/disadvantage of integrating GPU runtime
       support into the OS.
 \vspace{-0.5em}
 \item Enables the OS to use GPUs for computation.
 \vspace{-0.5em}
 \item Makes GPUs as first-class computing resources in time-sharing
       systems -- support for shared memory, memory swapping,
       and virtual GPUs, in addition to device memory management and GPU
       scheduling.
 \vspace{-0.5em}
 \item Provides open-source implementations of the GPU device driver,
       runtime/API libraries, utility tools, and Gdev resource
       management components.
 \vspace{-0.5em}
 \item Demonstrates the capabilities of Gdev using real-world benchmarks
       and applications.
 \vspace{-0.25em}
\end{itemize}

The rest of this paper is organized as follows.
Section~\ref{sec:model} provides the model and assumptions behind
this paper.
Section~\ref{sec:ecosystem} outlines the Gdev ecosystem.
Section~\ref{sec:memory_management} and \ref{sec:scheduling} propose new
memory management and scheduling schemes for the GPU.
Section~\ref{sec:implementation} describes a prototype implementation,
and its capabilities are demonstrated in Section~\ref{sec:evaluation}.
Related work are discussed in Section~\ref{sec:related_work}.
We provide our concluding remarks in Section~\ref{sec:conclusion}.

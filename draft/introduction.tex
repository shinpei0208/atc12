\section{Introduction}
\label{sec:introduction}

Recent innovations in heterogeneous compute devices with many-core
technology have continuously achieved orders-of-magnitude increases in
systems performance. 
In particular, the graphics processing unit (GPU) receives considerable
attention as a very powerful platform that embraces a concept of
many-core computing.
A recent announcement from the TOP500 supercomputing sites in November
2011~\cite{TOP500} disclosed that three of the top five supercomputers
use GPUs.
For example, scientific climate applications can gain 80x speedups using
such GPU-based supercomputers~\cite{Shimokawabe10}.
The benefits of GPUs appear not only in high-performance computing but
also in general-purpose and embedded computing domains.
According to previous research, GPUs can provide up to an order of 10x
speedups for software routers~\cite{Han_SIGCOMM10}, 20x speedups for
encrypted networks~\cite{Jang_NSDI11}, and 15x speedups for motion
planning in autonomous vehicles~\cite{McNaughton_ICRA11}.
Such a rapid growth of general-purpose computing on GPUs,
\textit{a.k.a.}, GPGPU, is encouraged by recent advances in GPU
programming languages, such as CUDA~\cite{CUDA40}.

Although the use of GPUs in general-purpose domains provides significant
performance improvements, system software support for GPUs in the market
is especially  tailored to accelerate particular applications dedicated
to the system, but is not well designed to integrate GPUs into more
general time-sharing systems.
Therefore, the research community has argued for the need to manage GPU
resources in the operating system (OS)~\cite{Bautin_MCNC08, Kato_ATC11,
Rossbach_SOSP11}.
However, these pieces of OS support still limit a class of applications
that can use GPUs due to a lack of first-class resource management
primitives, such as virtual memory management, inter-process
communication (IPC), and time-and-space partitioning.

On a time-sharing server where multiple independent users are logged in,
for instance, if one executes a high-workload GPGPU program, GPU
resources available for remaining users could be very limited. 
GPU schedulers in the state of the arts~\cite{Kato_ATC11,
Rossbach_SOSP11} provide priority schemes for GPUs, but users
are required to specify priorities and other parameters by themselves.
The system thus cannot partition GPU resources for independent sessions.

More essentially, the current GPGPU framework does not allow
users to share memory resources among GPU contexts, and could limit the
total amount of available data to the physical device memory size, which would pose non-trivial constraints in
general-purpose domains.
The current OS and system support for GPUs also leaves the
application programming interface (API) to the user space, which
restricts the availability of GPUs to user-space applications.
In addition, employing the API in the user-space library implies that
the device driver exposes its resource management primitives to the user
space through a system call, which allows malicious programs to control
GPUs through this system call. 
As a matter of fact, non-privileged user-space programs can directly
allocate memory and launch computation on NVIDIA GPUs using
\texttt{ioctl} calls in Linux.
Therefore, the API should also be protected by the OS.

This paper presents \textbf{Gdev}, a new GPU ecosystem that integrates
runtime support into the OS to allow a wide class of user-space
applications and the OS itself to use GPUs in a reliable manner.
Specifically, Gdev employs a set of low-level API functions for GPUs in
the OS.
While OS modules can directly call these functions, user-space
programs can also call them through a system call, such as
\texttt{ioctl()}.
We also provide an implementation of CUDA 4.0 API~\cite{CUDA40},
wrapping Gdev API, so that legacy CUDA applications can run with Gdev
both in the user space and OS. 
This runtime-unified OS approach forces all GPU applications running in
the same system to be managed by the identical resource management
entity, which eliminates the concern about malicious programs attempting
to access GPUs directly.
The contribution of Gdev also includes first-class support for
multi-tasking environments sharing GPUs.
Specifically, Gdev supports shared memory to allow programmers to
share device memory among multiple contexts explicitly through the API.
We also use this shared memory scheme to allow systems to allocate data
over the device memory size, exploiting implicit data eviction and
reloading between the host and device memory.
Gdev further contributes to GPU scheduling, particularly
to support virtual GPUs under the non-preemptive and burst nature of GPU
workloads.
As a proof-of-concept, we provide an open-source implementation of Gdev,
including a device driver, runtime library, and API library.
To summarize, this paper makes the following contributions:
\begin{itemize}
 \vspace{-0.25em}
 \item Identifies the advantage and disadvantage of GPU runtime support
       integrated in the OS.
 \vspace{-0.5em}
 \item Enables the OS to use GPUs for computation.
 \vspace{-0.5em}
 \item Makes GPUs as first-class computing resources in time-sharing
       systems -- support for shared memory, memory swapping,
       and virtual GPUs, in addition to device memory management and GPU
       scheduling.
 \vspace{-0.5em}
 \item Provides open-source implementations of the GPU device driver,
       runtime/API libraries, utility tools, and Gdev resource
       management components.
 \vspace{-0.5em}
 \item Demonstrates the capabilities of Gdev using well-known real-world
       benchmarks and applications.
 \vspace{-0.25em}
\end{itemize}

The rest of this paper is organized as follows.
The background and the system model behind this paper are described in
Section~\ref{sec:model}.
Section~\ref{sec:ecosystem} presents an overview of the Gdev ecosystem.
Section~\ref{sec:memory_management} and \ref{sec:scheduling} provide the
details of Gdev memory management and scheduling.
Section~\ref{sec:implementation} describes our prototype implementation,
and Section~\ref{sec:evaluation} shows its capabilities.
Section~\ref{sec:conclusion} concludes this paper.